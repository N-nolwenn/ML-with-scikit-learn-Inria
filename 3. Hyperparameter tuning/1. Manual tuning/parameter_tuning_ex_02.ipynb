{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f26384",
   "metadata": {},
   "source": [
    "# ðŸ“ Exercise M3.01\n",
    "\n",
    "The goal is to write an exhaustive search to find the best parameters\n",
    "combination maximizing the model generalization performance.\n",
    "\n",
    "Here we use a small subset of the Adult Census dataset to make the code faster\n",
    "to execute. Once your code works on the small subset, try to change\n",
    "`train_size` to a larger value (e.g. 0.8 for 80% instead of 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248f8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/master/datasets/adult-census.csv\"\n",
    "adult_census = pd.read_csv(url)\n",
    "\n",
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, train_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717048b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"cat_preprocessor\",\n",
    "            categorical_preprocessor,\n",
    "            selector(dtype_include=object),\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", HistGradientBoostingClassifier(random_state=42)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309cf92",
   "metadata": {},
   "source": [
    "Use the previously defined model (called `model`) and using two nested `for`\n",
    "loops, make a search of the best combinations of the `learning_rate` and\n",
    "`max_leaf_nodes` parameters. In this regard, you have to train and test the\n",
    "model by setting the parameters. The evaluation of the model should be\n",
    "performed using `cross_val_score` on the training set. Use the following\n",
    "parameters search:\n",
    "- `learning_rate` for the values 0.01, 0.1, 1 and 10. This parameter controls\n",
    "  the ability of a new tree to correct the error of the previous sequence of\n",
    "  trees\n",
    "- `max_leaf_nodes` for the values 3, 10, 30. This parameter controls the depth\n",
    "  of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12a8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop the warning\n",
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'  # Replace '4' with the number of cores you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ffad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with learning rate 0.010 and max leaf nodes 3... Found new best model with score 0.790!\n",
      "Evaluating model with learning rate 0.010 and max leaf nodes 10... Found new best model with score 0.814!\n",
      "Evaluating model with learning rate 0.010 and max leaf nodes 30... Found new best model with score 0.842!\n",
      "Evaluating model with learning rate 0.100 and max leaf nodes 3... Found new best model with score 0.849!\n",
      "Evaluating model with learning rate 0.100 and max leaf nodes 10... Found new best model with score 0.863!\n",
      "Evaluating model with learning rate 0.100 and max leaf nodes 30... Evaluating model with learning rate 1.000 and max leaf nodes 3... Evaluating model with learning rate 1.000 and max leaf nodes 10... Evaluating model with learning rate 1.000 and max leaf nodes 30... Evaluating model with learning rate 10.000 and max leaf nodes 3... Evaluating model with learning rate 10.000 and max leaf nodes 10... Evaluating model with learning rate 10.000 and max leaf nodes 30... \n",
      " The best accuracy obtained is 0.863\n",
      "The best parameters found are:\n",
      " {'learning_rate': 0.1, 'max_leaf_nodes': 10}\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "learning_rate= [0.01,0.1,1,10] # classifier__learning_rate\n",
    "max_leaf_nodes = [3, 10, 30] # classifier__max_leaf_nodes\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rate:\n",
    "    for mln in max_leaf_nodes:\n",
    "        print(\n",
    "            (\n",
    "                f\"Evaluating model with learning rate {lr:.3f}\"\n",
    "                f\" and max leaf nodes {mln}... \"\n",
    "            ),\n",
    "            end=\"\",\n",
    "        )\n",
    "        model.set_params(classifier__learning_rate = lr, classifier__max_leaf_nodes = mln)\n",
    "        cv_results = cross_validate(model, data_train, target_train)\n",
    "        scores = cv_results[\"test_score\"]\n",
    "        mean_score = scores.mean()\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = {\"learning_rate\": lr, \"max_leaf_nodes\": mln}\n",
    "            print(f\"Found new best model with score {best_score:.3f}!\")\n",
    "\n",
    "print(f\"\\n The best accuracy obtained is {best_score:.3f}\")\n",
    "print(f\"The best parameters found are:\\n {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adf2ac",
   "metadata": {},
   "source": [
    "Now use the test set to score the model using the best parameters that we\n",
    "found using cross-validation. You will have to refit the model over the full\n",
    "training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68ec6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score after the parameter tuning: 0.870\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "\n",
    "best_lr = best_params[\"learning_rate\"]\n",
    "best_mln = best_params[\"max_leaf_nodes\"]\n",
    "\n",
    "model.set_params(classifier__learning_rate = best_lr, classifier__max_leaf_nodes = best_mln)\n",
    "model.fit(data_train, target_train)\n",
    "\n",
    "test_score = model.score(data_test, target_test)\n",
    "print(f\"Test score after the parameter tuning: {test_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "nbreset": "https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/notebooks/parameter_tuning_ex_02.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
